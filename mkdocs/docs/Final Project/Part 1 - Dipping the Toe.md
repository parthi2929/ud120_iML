<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Final-Project">Final Project<a class="anchor-link" href="#Final-Project">&#182;</a></h2><p><strong>Goal</strong>:<br>
To classify POI out of enron email dataset.  To achieve accuracy such that, Precision and Recall are greater than 0.3 at least.</p>
<p><strong>Premise</strong>:<br>
There are 2 important starter files, given by Udacity.</p>
<ol>
<li>poi_id.py  - This is the file we would be working on creating the classifier. </li>
<li>tester.py  - This is simply file used to test our code  </li>
</ol>
<p><strong>Workflow Overview</strong>:<br>
This is just again a starter skeleton to structure our thinking process. We will add/modify/iterate as and when needed. Thus this is also not all, and complete as well.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">from</span> <span class="nn">graphviz</span> <span class="kn">import</span> <span class="n">Digraph</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">Digraph</span><span class="p">(</span><span class="s1">&#39;Work Flow&#39;</span><span class="p">,</span>  <span class="n">node_attr</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;shape&#39;</span><span class="p">:</span> <span class="s1">&#39;record&#39;</span><span class="p">})</span>
<span class="n">g</span><span class="o">.</span><span class="n">attr</span><span class="p">(</span><span class="n">rankdir</span><span class="o">=</span><span class="s1">&#39;LR&#39;</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="s1">&#39;step_1&#39;</span><span class="p">,</span> <span class="sa">r</span><span class="s1">&#39;1. Data\nPreProcessing&#39;</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="s1">&#39;step_2&#39;</span><span class="p">,</span> <span class="sa">r</span><span class="s1">&#39;2. Data\nStandardization&#39;</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="s1">&#39;step_3&#39;</span><span class="p">,</span> <span class="sa">r</span><span class="s1">&#39;3. Classifier\nTuning&#39;</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="s1">&#39;step_4&#39;</span><span class="p">,</span> <span class="sa">r</span><span class="s1">&#39;4. Evaluation\nMetrics&#39;</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">edges</span><span class="p">([(</span><span class="s1">&#39;step_1&#39;</span><span class="p">,</span><span class="s1">&#39;step_2&#39;</span><span class="p">),(</span><span class="s1">&#39;step_2&#39;</span><span class="p">,</span><span class="s1">&#39;step_3&#39;</span><span class="p">),(</span><span class="s1">&#39;step_3&#39;</span><span class="p">,</span><span class="s1">&#39;step_4&#39;</span><span class="p">)])</span>
<span class="n">g</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[1]:</div>



<div class="output_svg output_subarea output_execute_result">
<?xml version="1.0" encoding="UTF-8" standalone="no"?>

<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"

 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">

<!-- Generated by graphviz version 2.38.0 (20140413.2041)

 -->

<!-- Title: Work Flow Pages: 1 -->

<svg width="488pt" height="47pt"

 viewBox="0.00 0.00 488.00 47.00" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">

<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 43)">

<title>Work Flow</title>

<polygon fill="white" stroke="none" points="-4,4 -4,-43 484,-43 484,4 -4,4"/>

<!-- step_1 -->

<g id="node1" class="node"><title>step_1</title>

<polygon fill="none" stroke="black" points="0,-0.5 0,-38.5 97,-38.5 97,-0.5 0,-0.5"/>

<text text-anchor="middle" x="48.5" y="-23.3" font-family="Times New Roman,serif" font-size="14.00">1. Data</text>

<text text-anchor="middle" x="48.5" y="-8.3" font-family="Times New Roman,serif" font-size="14.00">PreProcessing</text>

</g>

<!-- step_2 -->

<g id="node2" class="node"><title>step_2</title>

<polygon fill="none" stroke="black" points="133,-0.5 133,-38.5 236,-38.5 236,-0.5 133,-0.5"/>

<text text-anchor="middle" x="184.5" y="-23.3" font-family="Times New Roman,serif" font-size="14.00">2. Data</text>

<text text-anchor="middle" x="184.5" y="-8.3" font-family="Times New Roman,serif" font-size="14.00">Standardization</text>

</g>

<!-- step_1&#45;&gt;step_2 -->

<g id="edge1" class="edge"><title>step_1&#45;&gt;step_2</title>

<path fill="none" stroke="black" d="M97.1207,-19.5C105.447,-19.5 114.211,-19.5 122.833,-19.5"/>

<polygon fill="black" stroke="black" points="122.855,-23.0001 132.855,-19.5 122.855,-16.0001 122.855,-23.0001"/>

</g>

<!-- step_3 -->

<g id="node3" class="node"><title>step_3</title>

<polygon fill="none" stroke="black" points="272,-0.5 272,-38.5 355,-38.5 355,-0.5 272,-0.5"/>

<text text-anchor="middle" x="313.5" y="-23.3" font-family="Times New Roman,serif" font-size="14.00">3. Classifier</text>

<text text-anchor="middle" x="313.5" y="-8.3" font-family="Times New Roman,serif" font-size="14.00">Tuning</text>

</g>

<!-- step_2&#45;&gt;step_3 -->

<g id="edge2" class="edge"><title>step_2&#45;&gt;step_3</title>

<path fill="none" stroke="black" d="M236.059,-19.5C244.517,-19.5 253.296,-19.5 261.759,-19.5"/>

<polygon fill="black" stroke="black" points="261.883,-23.0001 271.883,-19.5 261.883,-16.0001 261.883,-23.0001"/>

</g>

<!-- step_4 -->

<g id="node4" class="node"><title>step_4</title>

<polygon fill="none" stroke="black" points="391,-0.5 391,-38.5 480,-38.5 480,-0.5 391,-0.5"/>

<text text-anchor="middle" x="435.5" y="-23.3" font-family="Times New Roman,serif" font-size="14.00">4. Evaluation</text>

<text text-anchor="middle" x="435.5" y="-8.3" font-family="Times New Roman,serif" font-size="14.00">Metrics</text>

</g>

<!-- step_3&#45;&gt;step_4 -->

<g id="edge3" class="edge"><title>step_3&#45;&gt;step_4</title>

<path fill="none" stroke="black" d="M355.127,-19.5C363.248,-19.5 371.899,-19.5 380.392,-19.5"/>

<polygon fill="black" stroke="black" points="380.625,-23.0001 390.625,-19.5 380.625,-16.0001 380.625,-23.0001"/>

</g>

</g>

</svg>


</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Setup">Setup<a class="anchor-link" href="#Setup">&#182;</a></h2><p>Firstly let us make sure, given <code>poi_id.py</code> <em>(loaded here)</em> and <code>tester.py</code> <em>(in our current directory)</em> runs in current form and also to know what is the accuracy we are starting with.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="ch">#!/usr/bin/python</span>
<span class="c1"># poi_id.py</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;../tools/&quot;</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">feature_format</span> <span class="kn">import</span> <span class="n">featureFormat</span><span class="p">,</span> <span class="n">targetFeatureSplit</span>
<span class="kn">from</span> <span class="nn">tester</span> <span class="kn">import</span> <span class="n">dump_classifier_and_data</span>

<span class="c1">### Task 1: Select what features you&#39;ll use.</span>
<span class="c1">### features_list is a list of strings, each of which is a feature name.</span>
<span class="c1">### The first feature must be &quot;poi&quot;.</span>
<span class="n">features_list</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;poi&#39;</span><span class="p">,</span><span class="s1">&#39;salary&#39;</span><span class="p">]</span> <span class="c1"># You will need to use more features</span>

<span class="c1">### Load the dictionary containing the dataset</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;final_project_dataset.pkl&quot;</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">data_file</span><span class="p">:</span>
    <span class="n">data_dict</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">data_file</span><span class="p">)</span>

<span class="c1">### Task 2: Remove outliers</span>
<span class="c1">### Task 3: Create new feature(s)</span>
<span class="c1">### Store to my_dataset for easy export below.</span>
<span class="n">my_dataset</span> <span class="o">=</span> <span class="n">data_dict</span>

<span class="c1">### Extract features and labels from dataset for local testing</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">featureFormat</span><span class="p">(</span><span class="n">my_dataset</span><span class="p">,</span> <span class="n">features_list</span><span class="p">,</span> <span class="n">sort_keys</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="n">labels</span><span class="p">,</span> <span class="n">features</span> <span class="o">=</span> <span class="n">targetFeatureSplit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1">### Task 4: Try a varity of classifiers</span>
<span class="c1">### Please name your classifier clf for easy export below.</span>
<span class="c1">### Note that if you want to do PCA or other multi-stage operations,</span>
<span class="c1">### you&#39;ll need to use Pipelines. For more info:</span>
<span class="c1">### http://scikit-learn.org/stable/modules/pipeline.html</span>

<span class="c1"># Provided to give you a starting point. Try a variety of classifiers.</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>

<span class="c1">### Task 5: Tune your classifier to achieve better than .3 precision and recall </span>
<span class="c1">### using our testing script. Check the tester.py script in the final project</span>
<span class="c1">### folder for details on the evaluation method, especially the test_classifier</span>
<span class="c1">### function. Because of the small size of the dataset, the script uses</span>
<span class="c1">### stratified shuffle split cross validation. For more info: </span>
<span class="c1">### http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedShuffleSplit.html</span>

<span class="c1"># Example starting point. Try investigating other evaluation techniques!</span>
<span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">features_train</span><span class="p">,</span> <span class="n">features_test</span><span class="p">,</span> <span class="n">labels_train</span><span class="p">,</span> <span class="n">labels_test</span> <span class="o">=</span> \
    <span class="n">train_test_split</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1">### Task 6: Dump your classifier, dataset, and features_list so anyone can</span>
<span class="c1">### check your results. You do not need to change anything below, but make sure</span>
<span class="c1">### that the version of poi_id.py that you submit can be run on its own and</span>
<span class="c1">### generates the necessary .pkl files for validating your results.</span>

<span class="n">dump_classifier_and_data</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">my_dataset</span><span class="p">,</span> <span class="n">features_list</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\parthi2929\Anaconda3\envs\py2\lib\site-packages\sklearn\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  &#34;This module will be removed in 0.20.&#34;, DeprecationWarning)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># tester.py</span>
<span class="kn">from</span> <span class="nn">tester</span> <span class="kn">import</span> <span class="n">main</span>
<span class="n">main</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>GaussianNB(priors=None)

Accuracy: 0.25560	Precision: 0.18481	Recall: 0.79800	F1: 0.30011	F2: 0.47968
Total predictions: 10000
True positives: 1596	False positives: 7040	False negatives:  404	True negatives:  960

</pre>
</div>
</div>

<div class="output_area">

<div class="prompt output_prompt">Out[3]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>GaussianNB(priors=None)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Modularize">Modularize<a class="anchor-link" href="#Modularize">&#182;</a></h2><p>Recall is pretty impressive, but accuracy and precisions are pathetically low. Apparantly, Salary is not the only feature useful to identify POIs effectively.</p>
<p>We are going to repeat the entire process of <code>poi_id.py</code> for evaluation almost every time we come up with new findings. So we will modularize such that, we could just call the relevant functions instead to make it more readable.Below are the modularized functions to start with.</p>
<p>Note we will not finish one stage (out of 4 shown above) and then go next. We will do iterative developement going back and forth.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">def</span> <span class="nf">init</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Load the raw data_dict from Udacity&#39;s pickle data and return it</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">pickle</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;../tools/&quot;</span><span class="p">)</span>
    <span class="c1">### Load the dictionary containing the dataset</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;final_project_dataset.pkl&quot;</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">data_file</span><span class="p">:</span>
        <span class="n">data_dict</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">data_file</span><span class="p">)</span>
        
    <span class="k">return</span> <span class="n">data_dict</span>

<span class="k">def</span> <span class="nf">split_data</span><span class="p">(</span><span class="n">my_dataset</span><span class="p">,</span> <span class="n">features_list</span><span class="p">):</span>
    <span class="c1"># convert</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">featureFormat</span><span class="p">(</span><span class="n">my_dataset</span><span class="p">,</span> <span class="n">features_list</span><span class="p">,</span> <span class="n">sort_keys</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
    <span class="n">labels</span><span class="p">,</span> <span class="n">features</span> <span class="o">=</span> <span class="n">targetFeatureSplit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">labels</span><span class="p">,</span> <span class="n">features</span> 

<span class="k">def</span> <span class="nf">classify</span><span class="p">():</span>
    <span class="c1"># our classifier</span>
    <span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">clf</span>

<span class="kn">from</span> <span class="nn">IPython.utils.coloransi</span> <span class="kn">import</span> <span class="n">TermColors</span> <span class="k">as</span> <span class="n">color</span> <span class="c1"># just for color gimmicks on output</span>
<span class="kn">from</span> <span class="nn">tester</span> <span class="kn">import</span> <span class="n">dump_classifier_and_data</span><span class="p">,</span> <span class="n">main</span>

<span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">my_dataset</span><span class="p">,</span> <span class="n">features_list</span><span class="p">):</span>
    <span class="n">dump_classifier_and_data</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">my_dataset</span><span class="p">,</span> <span class="n">features_list</span><span class="p">)</span>
    <span class="k">print</span> <span class="s1">&#39;{1}Udacity</span><span class="se">\&#39;</span><span class="s1">s Evaluation:{0}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">color</span><span class="o">.</span><span class="n">Normal</span><span class="p">,</span> <span class="n">color</span><span class="o">.</span><span class="n">BlinkBlue</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">main</span><span class="p">()</span>  <span class="c1"># from tester.py</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we could modify <code>poi_id.py</code> as below</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">data_dict</span> <span class="o">=</span> <span class="n">init</span><span class="p">()</span>


<span class="c1"># PRE PROCESSING</span>


<span class="c1"># STANDARDIZATION</span>


<span class="c1"># CLASSIFIER</span>
<span class="n">features_list</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;poi&#39;</span><span class="p">,</span><span class="s1">&#39;salary&#39;</span><span class="p">]</span>
<span class="n">my_dataset</span> <span class="o">=</span> <span class="n">data_dict</span>
<span class="n">labels</span><span class="p">,</span> <span class="n">features</span> <span class="o">=</span> <span class="n">split_data</span><span class="p">(</span><span class="n">my_dataset</span><span class="p">,</span> <span class="n">features_list</span><span class="p">)</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">classify</span><span class="p">()</span>

<span class="c1"># EVALUATION</span>
<span class="n">evaluate</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">my_dataset</span><span class="p">,</span> <span class="n">features_list</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre><span class="ansi-blue-intense-fg ansi-bold">Udacity&#39;s Evaluation:</span>
GaussianNB(priors=None)

Accuracy: 0.25560	Precision: 0.18481	Recall: 0.79800	F1: 0.30011	F2: 0.47968
Total predictions: 10000
True positives: 1596	False positives: 7040	False negatives:  404	True negatives:  960

</pre>
</div>
</div>

<div class="output_area">

<div class="prompt output_prompt">Out[5]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>GaussianNB(priors=None)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Classifier">Classifier<a class="anchor-link" href="#Classifier">&#182;</a></h2><p>We already have Guassian in our starter code, but how do other contenders fare? Let us try 3 more.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">print</span> <span class="s1">&#39;{1}GaussianNB:{0}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">color</span><span class="o">.</span><span class="n">Normal</span><span class="p">,</span> <span class="n">color</span><span class="o">.</span><span class="n">BlinkBlue</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="n">dump_classifier_and_data</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">my_dataset</span><span class="p">,</span> <span class="n">features_list</span><span class="p">)</span>
<span class="n">main</span><span class="p">()</span>

<span class="k">print</span> <span class="s1">&#39;{1}SVC Untuned:{0}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">color</span><span class="o">.</span><span class="n">Normal</span><span class="p">,</span> <span class="n">color</span><span class="o">.</span><span class="n">BlinkBlue</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">()</span>
<span class="n">dump_classifier_and_data</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">my_dataset</span><span class="p">,</span> <span class="n">features_list</span><span class="p">)</span>
<span class="n">main</span><span class="p">()</span>

<span class="k">print</span> <span class="s1">&#39;{1}KMeans Untuned:{0}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">color</span><span class="o">.</span><span class="n">Normal</span><span class="p">,</span> <span class="n">color</span><span class="o">.</span><span class="n">BlinkBlue</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">dump_classifier_and_data</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">my_dataset</span><span class="p">,</span> <span class="n">features_list</span><span class="p">)</span>
<span class="n">main</span><span class="p">()</span>

<span class="k">print</span> <span class="s1">&#39;{1}Decision Tree Untuned:{0}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">color</span><span class="o">.</span><span class="n">Normal</span><span class="p">,</span> <span class="n">color</span><span class="o">.</span><span class="n">BlinkBlue</span><span class="p">)</span>
<span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">tree</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>
<span class="n">dump_classifier_and_data</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">my_dataset</span><span class="p">,</span> <span class="n">features_list</span><span class="p">)</span>  
<span class="n">_</span> <span class="o">=</span> <span class="n">main</span><span class="p">()</span>     <span class="c1"># we made tester.py to return trained clf so to avoid re printing classifier in ipython we assign to dummy</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre><span class="ansi-blue-intense-fg ansi-bold">GaussianNB:</span>
GaussianNB(priors=None)

Accuracy: 0.25560	Precision: 0.18481	Recall: 0.79800	F1: 0.30011	F2: 0.47968
Total predictions: 10000
True positives: 1596	False positives: 7040	False negatives:  404	True negatives:  960

<span class="ansi-blue-intense-fg ansi-bold">SVC Untuned:</span>
Total predictions: 10000
True positives:    0	False positives:   77	False negatives: 2000	True negatives: 7923
Got a divide by zero when trying out: SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=&#39;ovr&#39;, degree=3, gamma=&#39;auto&#39;, kernel=&#39;rbf&#39;,
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
Precision or recall may be undefined due to a lack of true positive predicitons.

<span class="ansi-blue-intense-fg ansi-bold">KMeans Untuned:</span>
KMeans(algorithm=&#39;auto&#39;, copy_x=True, init=&#39;k-means++&#39;, max_iter=300,
    n_clusters=2, n_init=10, n_jobs=1, precompute_distances=&#39;auto&#39;,
    random_state=None, tol=0.0001, verbose=0)

Accuracy: 0.77580	Precision: 0.20488	Recall: 0.04200	F1: 0.06971	F2: 0.04994
Total predictions: 10000
True positives:   84	False positives:  326	False negatives: 1916	True negatives: 7674

<span class="ansi-blue-intense-fg ansi-bold">Decision Tree Untuned:</span>
DecisionTreeClassifier(class_weight=None, criterion=&#39;gini&#39;, max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=0,
            splitter=&#39;best&#39;)

Accuracy: 0.69210	Precision: 0.23619	Recall: 0.24150	F1: 0.23881	F2: 0.24042
Total predictions: 10000
True positives:  483	False positives: 1562	False negatives: 1517	True negatives: 6438

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>SVC</code> outright failed, <code>KMeans</code> and <code>Decision Tree</code> are already giving much better accuracy. Before we pick one of <code>KMeans</code> or <code>Decision Tree</code>, let us check one more trap - <code>Zero Prediction Accuracy.</code></p>
<p><strong>What if our classifer always predicts non-POI?</strong> Let us find out with a dummy classifier. Note we are also starting to use pandas.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">my_dataset</span><span class="p">,</span> <span class="n">orient</span><span class="o">=</span><span class="s1">&#39;index&#39;</span><span class="p">)</span>

<span class="k">print</span> <span class="s1">&#39;Total no of records: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="k">print</span> <span class="s1">&#39;Total no of POIs: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;poi&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="bp">True</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="k">print</span> <span class="s1">&#39;Total no of POIs: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;poi&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="bp">False</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="kn">from</span> <span class="nn">sklearn.dummy</span> <span class="kn">import</span> <span class="n">DummyClassifier</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">DummyClassifier</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;constant&#39;</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">constant</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">dump_classifier_and_data</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">my_dataset</span><span class="p">,</span> <span class="n">features_list</span><span class="p">)</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">main</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Total no of records: 146
Total no of POIs: 18
Total no of POIs: 128
Total predictions: 10000
True positives:    0	False positives:    0	False negatives: 2000	True negatives: 8000
Got a divide by zero when trying out: DummyClassifier(constant=False, random_state=0, strategy=&#39;constant&#39;)
Precision or recall may be undefined due to a lack of true positive predicitons.

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Note out of 146 records, we have only 18 POIs, so intuitively, even if we always guess 'non POI' we should be right most of the times.</p>
<p>Remember:</p>
<div style="background-color:'#E3F2FD;  padding: 10px 10px 10px 10px;"><pre style="background-color:'#E3F2FD;">
True positives (TP):    Reality POI, Prediction POI.  
False positives (FP):   Reality non POI, Prediction POI.  
False negatives (FN):   Reality POI, Prediction non POI.  
True negatives (TN):    Reality non POI, Prediction non POI.</pre>  </div><p>Accuracy = No of predictions in reality and predicted are equal / Total no of predictions</p>
<p>Thus</p>
<p>$$ \displaystyle \text{Accuracy = }\frac{{\text{TP}\text{+TN}}}{{\text{TP+FP+FN+TN}}}=\frac{{0+8000}}{{0+0+2000+8000}}=\frac{{8000}}{{10000}}=80\text{  }\%$$</p>
<p>Ponder this, even if our model is simply not <em>predicting</em> anything per se, we get 80% accuracy.  This is why, Recall and Precision are important.</p>
<p>$$ \displaystyle \begin{array}{l}\text{Precision = }\dfrac{{\text{TP}}}{{\text{TP+FP}}}=\dfrac{0}{0}\\\text{Recall = }\dfrac{{\text{TP}}}{{\text{TP+FN}}}=\dfrac{0}{{2000}}=0\end{array}$$</p>
<p>Precision is incalculable and Recall is just 0. We are always wrongly labelling any POI that shows up in dataset as non-POI (FP) which is obviously inadmissable, and 0 Recall score indicates that.</p>
<p>It could be for similar reason, we cannot also currently proceed to using SVC at the moment (try checking out)</p>
<p>Comparing Recall and Precision between, <code>Decision Tree</code> fares better than <code>KMeans</code> so we shall go with that, though accuracy is as of now lower.</p>
<p>So far,</p>
<ol>
<li>We have set up the code </li>
<li>Chosen Decision Tree as our main classifier to proceed with</li>
<li>Understood, how better should our classifier fare than Zero prediction case (cross at least 80% accuracy)</li>
</ol>

</div>
</div>
</div>
</div>
</div>